# 🧠 PRODIGY_GenAI_03 – Image Captioning with BLIP

This is Task 3 of the **Generative AI Internship** at **Prodigy InfoTech**.

---

## 📌 Task Objective
To develop an image captioning system using the **BLIP (Bootstrapped Language Image Pretraining)** model. The goal is to generate meaningful textual descriptions for input images using a vision-language transformer model.

---

## 🧰 Tools & Libraries
- Python
- Google Colab
- Hugging Face Transformers
- `Salesforce/blip-image-captioning-base` model
- PIL (Python Imaging Library)
- Torch

---

## 🖼️ Sample Caption Output

**Input Image:**  
A woman sitting at a desk with a laptop

**Generated Caption:**

